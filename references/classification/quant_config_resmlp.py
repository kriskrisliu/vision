extra_config={

"q_resmlp_uniform8":{
"quant_input":8,
"stem.quant_act_conv":8,
"stem.proj":8,
"stem.norm":8,
"quant_act_int32":16,

"blocks.0.norm1":8,
"blocks.0.quant_norm1":8,
"blocks.0.linear_tokens":8,
"blocks.0.quant_mlp1":8,
"blocks.0.ls1":8,
"blocks.0.norm2":8,
"blocks.0.quant_norm2":8,
"blocks.0.mlp_channels.fc1":8,
"blocks.0.mlp_channels.quant_fc":8,
"blocks.0.mlp_channels.quant_act":8,
"blocks.0.mlp_channels.fc2":8,
"blocks.0.quant_mlp2":8,
"blocks.0.ls2":8,
"blocks.0.quant_act_int32_tokens":16,
"blocks.0.quant_act_int32_channels":16,

"blocks.1.norm1": 8 ,
"blocks.1.quant_norm1": 8 ,
"blocks.1.linear_tokens": 8 ,
"blocks.1.quant_mlp1": 8 ,
"blocks.1.ls1": 8 ,
"blocks.1.norm2": 8 ,
"blocks.1.quant_norm2": 8 ,
"blocks.1.mlp_channels.fc1": 8 ,
"blocks.1.mlp_channels.quant_fc": 8 ,
"blocks.1.mlp_channels.quant_act": 8 ,
"blocks.1.mlp_channels.fc2": 8 ,
"blocks.1.quant_mlp2": 8 ,
"blocks.1.ls2": 8 ,
"blocks.1.quant_act_int32_tokens": 16 ,
"blocks.1.quant_act_int32_channels": 16 ,

"blocks.2.norm1": 8 ,
"blocks.2.quant_norm1": 8 ,
"blocks.2.linear_tokens": 8 ,
"blocks.2.quant_mlp1": 8 ,
"blocks.2.ls1": 8 ,
"blocks.2.norm2": 8 ,
"blocks.2.quant_norm2": 8 ,
"blocks.2.mlp_channels.fc1": 8 ,
"blocks.2.mlp_channels.quant_fc": 8 ,
"blocks.2.mlp_channels.quant_act": 8 ,
"blocks.2.mlp_channels.fc2": 8 ,
"blocks.2.quant_mlp2": 8 ,
"blocks.2.ls2": 8 ,
"blocks.2.quant_act_int32_tokens": 16 ,
"blocks.2.quant_act_int32_channels": 16 ,

"blocks.3.norm1": 8 ,
"blocks.3.quant_norm1": 8 ,
"blocks.3.linear_tokens": 8 ,
"blocks.3.quant_mlp1": 8 ,
"blocks.3.ls1": 8 ,
"blocks.3.norm2": 8 ,
"blocks.3.quant_norm2": 8 ,
"blocks.3.mlp_channels.fc1": 8 ,
"blocks.3.mlp_channels.quant_fc": 8 ,
"blocks.3.mlp_channels.quant_act": 8 ,
"blocks.3.mlp_channels.fc2": 8 ,
"blocks.3.quant_mlp2": 8 ,
"blocks.3.ls2": 8 ,
"blocks.3.quant_act_int32_tokens": 16 ,
"blocks.3.quant_act_int32_channels": 16 ,

"blocks.4.norm1": 8 ,
"blocks.4.quant_norm1": 8 ,
"blocks.4.linear_tokens": 8 ,
"blocks.4.quant_mlp1": 8 ,
"blocks.4.ls1": 8 ,
"blocks.4.norm2": 8 ,
"blocks.4.quant_norm2": 8 ,
"blocks.4.mlp_channels.fc1": 8 ,
"blocks.4.mlp_channels.quant_fc": 8 ,
"blocks.4.mlp_channels.quant_act": 8 ,
"blocks.4.mlp_channels.fc2": 8 ,
"blocks.4.quant_mlp2": 8 ,
"blocks.4.ls2": 8 ,
"blocks.4.quant_act_int32_tokens": 16 ,
"blocks.4.quant_act_int32_channels": 16 ,

"blocks.5.norm1": 8 ,
"blocks.5.quant_norm1": 8 ,
"blocks.5.linear_tokens": 8 ,
"blocks.5.quant_mlp1": 8 ,
"blocks.5.ls1": 8 ,
"blocks.5.norm2": 8 ,
"blocks.5.quant_norm2": 8 ,
"blocks.5.mlp_channels.fc1": 8 ,
"blocks.5.mlp_channels.quant_fc": 8 ,
"blocks.5.mlp_channels.quant_act": 8 ,
"blocks.5.mlp_channels.fc2": 8 ,
"blocks.5.quant_mlp2": 8 ,
"blocks.5.ls2": 8 ,
"blocks.5.quant_act_int32_tokens": 16 ,
"blocks.5.quant_act_int32_channels": 16 ,

"blocks.6.norm1": 8 ,
"blocks.6.quant_norm1": 8 ,
"blocks.6.linear_tokens": 8 ,
"blocks.6.quant_mlp1": 8 ,
"blocks.6.ls1": 8 ,
"blocks.6.norm2": 8 ,
"blocks.6.quant_norm2": 8 ,
"blocks.6.mlp_channels.fc1": 8 ,
"blocks.6.mlp_channels.quant_fc": 8 ,
"blocks.6.mlp_channels.quant_act": 8 ,
"blocks.6.mlp_channels.fc2": 8 ,
"blocks.6.quant_mlp2": 8 ,
"blocks.6.ls2": 8 ,
"blocks.6.quant_act_int32_tokens": 16 ,
"blocks.6.quant_act_int32_channels": 16 ,

"blocks.7.norm1": 8 ,
"blocks.7.quant_norm1": 8 ,
"blocks.7.linear_tokens": 8 ,
"blocks.7.quant_mlp1": 8 ,
"blocks.7.ls1": 8 ,
"blocks.7.norm2": 8 ,
"blocks.7.quant_norm2": 8 ,
"blocks.7.mlp_channels.fc1": 8 ,
"blocks.7.mlp_channels.quant_fc": 8 ,
"blocks.7.mlp_channels.quant_act": 8 ,
"blocks.7.mlp_channels.fc2": 8 ,
"blocks.7.quant_mlp2": 8 ,
"blocks.7.ls2": 8 ,
"blocks.7.quant_act_int32_tokens": 16 ,
"blocks.7.quant_act_int32_channels": 16 ,

"blocks.8.norm1": 8 ,
"blocks.8.quant_norm1": 8 ,
"blocks.8.linear_tokens": 8 ,
"blocks.8.quant_mlp1": 8 ,
"blocks.8.ls1": 8 ,
"blocks.8.norm2": 8 ,
"blocks.8.quant_norm2": 8 ,
"blocks.8.mlp_channels.fc1": 8 ,
"blocks.8.mlp_channels.quant_fc": 8 ,
"blocks.8.mlp_channels.quant_act": 8 ,
"blocks.8.mlp_channels.fc2": 8 ,
"blocks.8.quant_mlp2": 8 ,
"blocks.8.ls2": 8 ,
"blocks.8.quant_act_int32_tokens": 16 ,
"blocks.8.quant_act_int32_channels": 16 ,

"blocks.9.norm1": 8 ,
"blocks.9.quant_norm1": 8 ,
"blocks.9.linear_tokens": 8 ,
"blocks.9.quant_mlp1": 8 ,
"blocks.9.ls1": 8 ,
"blocks.9.norm2": 8 ,
"blocks.9.quant_norm2": 8 ,
"blocks.9.mlp_channels.fc1": 8 ,
"blocks.9.mlp_channels.quant_fc": 8 ,
"blocks.9.mlp_channels.quant_act": 8 ,
"blocks.9.mlp_channels.fc2": 8 ,
"blocks.9.quant_mlp2": 8 ,
"blocks.9.ls2": 8 ,
"blocks.9.quant_act_int32_tokens": 16 ,
"blocks.9.quant_act_int32_channels": 16 ,

"blocks.10.norm1": 8 ,
"blocks.10.quant_norm1": 8 ,
"blocks.10.linear_tokens": 8 ,
"blocks.10.quant_mlp1": 8 ,
"blocks.10.ls1": 8 ,
"blocks.10.norm2": 8 ,
"blocks.10.quant_norm2": 8 ,
"blocks.10.mlp_channels.fc1": 8 ,
"blocks.10.mlp_channels.quant_fc": 8 ,
"blocks.10.mlp_channels.quant_act": 8 ,
"blocks.10.mlp_channels.fc2": 8 ,
"blocks.10.quant_mlp2": 8 ,
"blocks.10.ls2": 8 ,
"blocks.10.quant_act_int32_tokens": 16 ,
"blocks.10.quant_act_int32_channels": 16 ,

"blocks.11.norm1": 8 ,
"blocks.11.quant_norm1": 8 ,
"blocks.11.linear_tokens": 8 ,
"blocks.11.quant_mlp1": 8 ,
"blocks.11.ls1": 8 ,
"blocks.11.norm2": 8 ,
"blocks.11.quant_norm2": 8 ,
"blocks.11.mlp_channels.fc1": 8 ,
"blocks.11.mlp_channels.quant_fc": 8 ,
"blocks.11.mlp_channels.quant_act": 8 ,
"blocks.11.mlp_channels.fc2": 8 ,
"blocks.11.quant_mlp2": 8 ,
"blocks.11.ls2": 8 ,
"blocks.11.quant_act_int32_tokens": 16 ,
"blocks.11.quant_act_int32_channels": 16 ,

"blocks.12.norm1": 8 ,
"blocks.12.quant_norm1": 8 ,
"blocks.12.linear_tokens": 8 ,
"blocks.12.quant_mlp1": 8 ,
"blocks.12.ls1": 8 ,
"blocks.12.norm2": 8 ,
"blocks.12.quant_norm2": 8 ,
"blocks.12.mlp_channels.fc1": 8 ,
"blocks.12.mlp_channels.quant_fc": 8 ,
"blocks.12.mlp_channels.quant_act": 8 ,
"blocks.12.mlp_channels.fc2": 8 ,
"blocks.12.quant_mlp2": 8 ,
"blocks.12.ls2": 8 ,
"blocks.12.quant_act_int32_tokens": 16 ,
"blocks.12.quant_act_int32_channels": 16 ,

"blocks.13.norm1": 8 ,
"blocks.13.quant_norm1": 8 ,
"blocks.13.linear_tokens": 8 ,
"blocks.13.quant_mlp1": 8 ,
"blocks.13.ls1": 8 ,
"blocks.13.norm2": 8 ,
"blocks.13.quant_norm2": 8 ,
"blocks.13.mlp_channels.fc1": 8 ,
"blocks.13.mlp_channels.quant_fc": 8 ,
"blocks.13.mlp_channels.quant_act": 8 ,
"blocks.13.mlp_channels.fc2": 8 ,
"blocks.13.quant_mlp2": 8 ,
"blocks.13.ls2": 8 ,
"blocks.13.quant_act_int32_tokens": 16 ,
"blocks.13.quant_act_int32_channels": 16 ,
"blocks.14.norm1": 8 ,
"blocks.14.quant_norm1": 8 ,
"blocks.14.linear_tokens": 8 ,
"blocks.14.quant_mlp1": 8 ,
"blocks.14.ls1": 8 ,
"blocks.14.norm2": 8 ,
"blocks.14.quant_norm2": 8 ,
"blocks.14.mlp_channels.fc1": 8 ,
"blocks.14.mlp_channels.quant_fc": 8 ,
"blocks.14.mlp_channels.quant_act": 8 ,
"blocks.14.mlp_channels.fc2": 8 ,
"blocks.14.quant_mlp2": 8 ,
"blocks.14.ls2": 8 ,
"blocks.14.quant_act_int32_tokens": 16 ,
"blocks.14.quant_act_int32_channels": 16 ,
"blocks.15.norm1": 8 ,
"blocks.15.quant_norm1": 8 ,
"blocks.15.linear_tokens": 8 ,
"blocks.15.quant_mlp1": 8 ,
"blocks.15.ls1": 8 ,
"blocks.15.norm2": 8 ,
"blocks.15.quant_norm2": 8 ,
"blocks.15.mlp_channels.fc1": 8 ,
"blocks.15.mlp_channels.quant_fc": 8 ,
"blocks.15.mlp_channels.quant_act": 8 ,
"blocks.15.mlp_channels.fc2": 8 ,
"blocks.15.quant_mlp2": 8 ,
"blocks.15.ls2": 8 ,
"blocks.15.quant_act_int32_tokens": 16 ,
"blocks.15.quant_act_int32_channels": 16 ,
"blocks.16.norm1": 8 ,
"blocks.16.quant_norm1": 8 ,
"blocks.16.linear_tokens": 8 ,
"blocks.16.quant_mlp1": 8 ,
"blocks.16.ls1": 8 ,
"blocks.16.norm2": 8 ,
"blocks.16.quant_norm2": 8 ,
"blocks.16.mlp_channels.fc1": 8 ,
"blocks.16.mlp_channels.quant_fc": 8 ,
"blocks.16.mlp_channels.quant_act": 8 ,
"blocks.16.mlp_channels.fc2": 8 ,
"blocks.16.quant_mlp2": 8 ,
"blocks.16.ls2": 8 ,
"blocks.16.quant_act_int32_tokens": 16 ,
"blocks.16.quant_act_int32_channels": 16 ,
"blocks.17.norm1": 8 ,
"blocks.17.quant_norm1": 8 ,
"blocks.17.linear_tokens": 8 ,
"blocks.17.quant_mlp1": 8 ,
"blocks.17.ls1": 8 ,
"blocks.17.norm2": 8 ,
"blocks.17.quant_norm2": 8 ,
"blocks.17.mlp_channels.fc1": 8 ,
"blocks.17.mlp_channels.quant_fc": 8 ,
"blocks.17.mlp_channels.quant_act": 8 ,
"blocks.17.mlp_channels.fc2": 8 ,
"blocks.17.quant_mlp2": 8 ,
"blocks.17.ls2": 8 ,
"blocks.17.quant_act_int32_tokens": 16 ,
"blocks.17.quant_act_int32_channels": 16 ,
"blocks.18.norm1": 8 ,
"blocks.18.quant_norm1": 8 ,
"blocks.18.linear_tokens": 8 ,
"blocks.18.quant_mlp1": 8 ,
"blocks.18.ls1": 8 ,
"blocks.18.norm2": 8 ,
"blocks.18.quant_norm2": 8 ,
"blocks.18.mlp_channels.fc1": 8 ,
"blocks.18.mlp_channels.quant_fc": 8 ,
"blocks.18.mlp_channels.quant_act": 8 ,
"blocks.18.mlp_channels.fc2": 8 ,
"blocks.18.quant_mlp2": 8 ,
"blocks.18.ls2": 8 ,
"blocks.18.quant_act_int32_tokens": 16 ,
"blocks.18.quant_act_int32_channels": 16 ,
"blocks.19.norm1": 8 ,
"blocks.19.quant_norm1": 8 ,
"blocks.19.linear_tokens": 8 ,
"blocks.19.quant_mlp1": 8 ,
"blocks.19.ls1": 8 ,
"blocks.19.norm2": 8 ,
"blocks.19.quant_norm2": 8 ,
"blocks.19.mlp_channels.fc1": 8 ,
"blocks.19.mlp_channels.quant_fc": 8 ,
"blocks.19.mlp_channels.quant_act": 8 ,
"blocks.19.mlp_channels.fc2": 8 ,
"blocks.19.quant_mlp2": 8 ,
"blocks.19.ls2": 8 ,
"blocks.19.quant_act_int32_tokens": 16 ,
"blocks.19.quant_act_int32_channels": 16 ,
"blocks.20.norm1": 8 ,
"blocks.20.quant_norm1": 8 ,
"blocks.20.linear_tokens": 8 ,
"blocks.20.quant_mlp1": 8 ,
"blocks.20.ls1": 8 ,
"blocks.20.norm2": 8 ,
"blocks.20.quant_norm2": 8 ,
"blocks.20.mlp_channels.fc1": 8 ,
"blocks.20.mlp_channels.quant_fc": 8 ,
"blocks.20.mlp_channels.quant_act": 8 ,
"blocks.20.mlp_channels.fc2": 8 ,
"blocks.20.quant_mlp2": 8 ,
"blocks.20.ls2": 8 ,
"blocks.20.quant_act_int32_tokens": 16 ,
"blocks.20.quant_act_int32_channels": 16 ,
"blocks.21.norm1": 8 ,
"blocks.21.quant_norm1": 8 ,
"blocks.21.linear_tokens": 8 ,
"blocks.21.quant_mlp1": 8 ,
"blocks.21.ls1": 8 ,
"blocks.21.norm2": 8 ,
"blocks.21.quant_norm2": 8 ,
"blocks.21.mlp_channels.fc1": 8 ,
"blocks.21.mlp_channels.quant_fc": 8 ,
"blocks.21.mlp_channels.quant_act": 8 ,
"blocks.21.mlp_channels.fc2": 8 ,
"blocks.21.quant_mlp2": 8 ,
"blocks.21.ls2": 8 ,
"blocks.21.quant_act_int32_tokens": 16 ,
"blocks.21.quant_act_int32_channels": 16 ,
"blocks.22.norm1": 8 ,
"blocks.22.quant_norm1": 8 ,
"blocks.22.linear_tokens": 8 ,
"blocks.22.quant_mlp1": 8 ,
"blocks.22.ls1": 8 ,
"blocks.22.norm2": 8 ,
"blocks.22.quant_norm2": 8 ,
"blocks.22.mlp_channels.fc1": 8 ,
"blocks.22.mlp_channels.quant_fc": 8 ,
"blocks.22.mlp_channels.quant_act": 8 ,
"blocks.22.mlp_channels.fc2": 8 ,
"blocks.22.quant_mlp2": 8 ,
"blocks.22.ls2": 8 ,
"blocks.22.quant_act_int32_tokens": 16 ,
"blocks.22.quant_act_int32_channels": 16 ,
"blocks.23.norm1": 8 ,
"blocks.23.quant_norm1": 8 ,
"blocks.23.linear_tokens": 8 ,
"blocks.23.quant_mlp1": 8 ,
"blocks.23.ls1": 8 ,
"blocks.23.norm2": 8 ,
"blocks.23.quant_norm2": 8 ,
"blocks.23.mlp_channels.fc1": 8 ,
"blocks.23.mlp_channels.quant_fc": 8 ,
"blocks.23.mlp_channels.quant_act": 8 ,
"blocks.23.mlp_channels.fc2": 8 ,
"blocks.23.quant_mlp2": 8 ,
"blocks.23.ls2": 8 ,
"blocks.23.quant_act_int32_tokens": 16 ,
"blocks.23.quant_act_int32_channels": 16 ,

"norm":8,
"quant_norm":8,
"head":8,
},
}
